{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Neural Networks\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons\n",
    "A neuron is just a container for weights, a bias, and an activation function. It takes a number of inputs, combines them, and produces a scalar output. The number of weights is determined by the number of inputs (features) to that neuron. The activation function allows for more complex mapping of inputs to the output (and so that layers of neurons don't reduce to a single linear combination). The code defining a neuron is here:\n",
    "\n",
    "```julia\n",
    "    mutable struct Neuron{T<:AbstractFloat,F<:Union{Function,Nothing}}\n",
    "        w::Vector{Value{T}}\n",
    "        b::Value{T}\n",
    "        activation::F\n",
    "    end\n",
    "```\n",
    "We can define a function to make variables of this type \"callable\": `n(X)`\n",
    "\n",
    "```julia\n",
    "    function (n::Neuron)(x)\n",
    "        if length(x) != length(n.w)\n",
    "            error(\"In calling n(x), expected $(length(n.w)) inputs to neuron, got $(length(x)):\\n\\tx = $(x)\")\n",
    "        end\n",
    "        raw = sum(n.w .* x)+ n.b\n",
    "        isnothing(n.activation) && return raw \n",
    "        return n.activation(raw)\n",
    "    end\n",
    "```\n",
    "This just computes the inner product of X and the weights, adds b, and then runs the result through an activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.41 (gr: 0.0, op: +)\n"
     ]
    }
   ],
   "source": [
    "using Micrograd\n",
    "\n",
    "## make a linear neuron with three inputs and call it\n",
    "n = neuron(3,nothing)\n",
    "x = [1.0,2.0,1.0]\n",
    "o = n(x)\n",
    "println(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tree:\n",
      "----- \n",
      "\n",
      "-0.41 (gr: 0.0, op: +)   \n",
      "|------------------------|\n",
      "-0.11 (gr: 0.0, op:  )   -0.3 (gr: 0.0, op: +)   \n",
      "                         |----------------------------------------------|\n",
      "                         0.47 (gr: 0.0, op: *)                          -0.77 (gr: 0.0, op: +)   \n",
      "                         |----------------------|                       |-----------------------------------------------|\n",
      "                         1.0 (gr: 0.0, op:  )   0.47 (gr: 0.0, op:  )   -0.31 (gr: 0.0, op: *)                          -0.45 (gr: 0.0, op: *)   \n",
      "                                                                        |----------------------|                        |----------------------|\n",
      "                                                                        2.0 (gr: 0.0, op:  )   -0.16 (gr: 0.0, op:  )   1.0 (gr: 0.0, op:  )   -0.45 (gr: 0.0, op:  )   "
     ]
    }
   ],
   "source": [
    "# now let's look at the tree\n",
    "nodes,depth = buildgraph(o)\n",
    "printgraph(nodes,depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ErrorException(\"In calling n(x), expected 3 inputs to neuron, got 2:\\n\\tx = [1.0, 2.0]\")\n",
      "\n",
      " ^ correctly throws error\n"
     ]
    }
   ],
   "source": [
    "# you can't give the wrong number of inputs\n",
    "try\n",
    "    n([1.0,2.0])\n",
    "catch e\n",
    "    println(e)\n",
    "    println(\"\\n ^ correctly throws error\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tree:\n",
      "----- \n",
      "\n",
      "0.0 (gr: 0.0, op: relu)   \n",
      "|\n",
      "-1.6 (gr: 0.0, op: +)   \n",
      "|-----------------------|\n",
      "0.87 (gr: 0.0, op:  )   -2.5 (gr: 0.0, op: +)   \n",
      "                        |-----------------------------------------------|\n",
      "                        -0.72 (gr: 0.0, op: *)                          -1.8 (gr: 0.0, op: +)   \n",
      "                        |----------------------|                        |-----------------------------------------------|\n",
      "                        1.0 (gr: 0.0, op:  )   -0.72 (gr: 0.0, op:  )   -1.5 (gr: 0.0, op: *)                           -0.25 (gr: 0.0, op: *)   \n",
      "                                                                        |----------------------|                        |----------------------|\n",
      "                                                                        2.0 (gr: 0.0, op:  )   -0.77 (gr: 0.0, op:  )   1.0 (gr: 0.0, op:  )   -0.25 (gr: 0.0, op:  )   "
     ]
    }
   ],
   "source": [
    "## make a relu activation neuron with three inputs and call it\n",
    "# note the op here is now relu instead of +\n",
    "# run this multiple times to see relu effect on a negative value\n",
    "n = neuron(3,relu)\n",
    "x = [1.0,2.0,1.0]\n",
    "o = n(x) \n",
    "\n",
    "nodes,depth = buildgraph(o)\n",
    "printgraph(nodes,depth)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "Layers are just groups of neurons, all with the same inputs (or at least here with fully connected layers). They essentially map from N dimensional input to M dimensional outputs where N is the number of inputs to each neuron in the layer and M is the number of neurons in the layer (recall each neuron has one output).\n",
    "\n",
    "The code is here:\n",
    "```julia\n",
    "mutable struct Layer{T<:AbstractFloat,F<:Union{Function,Nothing}}\n",
    "    neurons::Vector{Neuron{T,F}}\n",
    "    inputs::Int\n",
    "    outputs::Int\n",
    "end\n",
    "```\n",
    "\n",
    "and again we make the layer callable:\n",
    "\n",
    "```julia\n",
    "function (l::Layer)(x)\n",
    "    out = [n(x) for n in l.neurons]\n",
    "    length(out) == 1 && return out[1]\n",
    "    return out\n",
    "end\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tree:\n",
      "----- \n",
      "\n",
      "0.0 (gr: 0.0, op: relu)   \n",
      "|\n",
      "-1.0 (gr: 0.0, op: +)   \n",
      "|-----------------------|\n",
      "0.88 (gr: 0.0, op:  )   -1.9 (gr: 0.0, op: +)   \n",
      "                        |-----------------------------------------------|\n",
      "                        -0.55 (gr: 0.0, op: *)                          -1.3 (gr: 0.0, op: +)   \n",
      "                        |----------------------|                        |-----------------------------------------------|\n",
      "                        1.0 (gr: 0.0, op:  )   -0.55 (gr: 0.0, op:  )   -0.72 (gr: 0.0, op: *)                          -0.6 (gr: 0.0, op: *)   \n",
      "                                                                        |----------------------|                        |----------------------|\n",
      "                                                                        2.0 (gr: 0.0, op:  )   -0.36 (gr: 0.0, op:  )   1.0 (gr: 0.0, op:  )   -0.6 (gr: 0.0, op:  )   "
     ]
    }
   ],
   "source": [
    "## make a layer of a single neuron with relu activation\n",
    "# this is just a layer wrapper for one neuron to make sure the API works and not break the printing\n",
    "l = layer(3,1,relu)\n",
    "o = l(x)\n",
    "\n",
    "nodes,depth = buildgraph(o)\n",
    "printgraph(nodes,depth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptrons\n",
    "\n",
    "These are simply lists of layers where the output of one is the input to the next. This means the n_in and n_out have to line up in the series. \n",
    "\n",
    "Here's the simple definition of the MLP type:\n",
    "```julia\n",
    "mutable struct MLP\n",
    "    layers::Vector{Layer}\n",
    "end\n",
    "```\n",
    "\n",
    "The constructor takes how many inputs (from the features in the data set) and a list of how many neurons per layer and makes sure the ins and outs line up.\n",
    "\n",
    "```julia\n",
    "function mlp(n_in,n_outs,act=relu)\n",
    "    n_vec = [n_in;n_outs]\n",
    "    MLP([i!= length(n_outs) ? layer(n_vec[i],n_vec[i+1],act) : layer(n_vec[i],n_vec[i+1],nothing) for i in 1:length(n_outs)])\n",
    "end\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "At the end, we need to make sure the output maps to the correct domain for our problem. That's why the last one has a linear output. We don't want to truncate the domain with an activation function by default.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a NN\n",
    "\n",
    "Instead of showing a simple MLP which is impossible to print with the tools in this package, we'll define the same one used in Micrograd to classify the sklearn moons data.\n",
    "\n",
    "This is an MLP that takes in 2D points and predicts a binary class. It uses 3 layers of 16 (relu), 16 (relu), and 1 (linear). The ending linear layer makes sure we can actually calculate hinge loss. Try setting it to relu and notice it won't fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\tLoss: 1.8\tAccuracy: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\tLoss: 6.9\tAccuracy: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2\tLoss: 0.64\tAccuracy: 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 3\tLoss: 0.73\tAccuracy: 0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4\tLoss: 0.87\tAccuracy: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5\tLoss: 0.63\tAccuracy: 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 6\tLoss: 0.45\tAccuracy: 0.77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 7\tLoss: 0.41\tAccuracy: 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8\tLoss: 0.38\tAccuracy: 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 9\tLoss: 0.36\tAccuracy: 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 10\tLoss: 0.34\tAccuracy: 0.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 11\tLoss: 0.33\tAccuracy: 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 12\tLoss: 0.31\tAccuracy: 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 13\tLoss: 0.3\tAccuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 14\tLoss: 0.29\tAccuracy: 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 15\tLoss: 0.27\tAccuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 16\tLoss: 0.25\tAccuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 17\tLoss: 0.24\tAccuracy: 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 18\tLoss: 0.22\tAccuracy: 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 19\tLoss: 0.23\tAccuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 20\tLoss: 0.23\tAccuracy: 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 21\tLoss: 0.3\tAccuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 22\tLoss: 0.39\tAccuracy: 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 23\tLoss: 0.27\tAccuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 24\tLoss: 0.21\tAccuracy: 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 25\tLoss: 0.17\tAccuracy: 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 26\tLoss: 0.16\tAccuracy: 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 27\tLoss: 0.17\tAccuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 28\tLoss: 0.15\tAccuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 29\tLoss: 0.19\tAccuracy: 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 30\tLoss: 0.16\tAccuracy: 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 31\tLoss: 0.14\tAccuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 32\tLoss: 0.1\tAccuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 33\tLoss: 0.11\tAccuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 34\tLoss: 0.078\tAccuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 35\tLoss: 0.099\tAccuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 36\tLoss: 0.085\tAccuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 37\tLoss: 0.12\tAccuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 38\tLoss: 0.056\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 39\tLoss: 0.042\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 40\tLoss: 0.045\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 41\tLoss: 0.085\tAccuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 42\tLoss: 0.13\tAccuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 43\tLoss: 0.074\tAccuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 44\tLoss: 0.053\tAccuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 45\tLoss: 0.034\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 46\tLoss: 0.034\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 47\tLoss: 0.051\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 48\tLoss: 0.11\tAccuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 49\tLoss: 0.063\tAccuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50\tLoss: 0.032\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 51\tLoss: 0.03\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 52\tLoss: 0.031\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 53\tLoss: 0.038\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 54\tLoss: 0.028\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 55\tLoss: 0.033\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 56\tLoss: 0.031\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 57\tLoss: 0.033\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 58\tLoss: 0.022\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 59\tLoss: 0.029\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 60\tLoss: 0.019\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 61\tLoss: 0.021\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 62\tLoss: 0.028\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 63\tLoss: 0.018\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 64\tLoss: 0.019\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 65\tLoss: 0.028\tAccuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 66\tLoss: 0.018\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 67\tLoss: 0.017\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 68\tLoss: 0.021\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 69\tLoss: 0.018\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 70\tLoss: 0.025\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 71\tLoss: 0.017\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 72\tLoss: 0.016\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 73\tLoss: 0.016\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 74\tLoss: 0.017\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 75\tLoss: 0.015\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 76\tLoss: 0.017\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 77\tLoss: 0.021\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 78\tLoss: 0.016\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 79\tLoss: 0.015\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 80\tLoss: 0.015\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 81\tLoss: 0.017\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 82\tLoss: 0.015\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 83\tLoss: 0.015\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 84\tLoss: 0.016\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 85\tLoss: 0.015\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 86\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 87\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 88\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 89\tLoss: 0.016\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 90\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 91\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 92\tLoss: 0.015\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 93\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 94\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 95\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 96\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 97\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 98\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 99\tLoss: 0.014\tAccuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "X,y = getmoons()\n",
    "m = mlp(2, [16, 16, 1])\n",
    "\n",
    "\n",
    "fit(m,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×2 Matrix{Float64}:\n",
       " -1.0  -1.0\n",
       " -1.0  -1.0\n",
       "  1.0   1.0\n",
       " -1.0  -1.0\n",
       "  1.0   1.0\n",
       "  1.0   1.0\n",
       "  1.0   1.0\n",
       "  1.0   1.0\n",
       "  1.0   1.0\n",
       " -1.0  -1.0\n",
       "  ⋮    \n",
       "  1.0   1.0\n",
       "  1.0   1.0\n",
       "  1.0   1.0\n",
       "  1.0   1.0\n",
       "  1.0   1.0\n",
       " -1.0  -1.0\n",
       "  1.0   1.0\n",
       "  1.0   1.0\n",
       " -1.0  -1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ok there's no plotting library. this is not quite as satisfying.\n",
    "y_fit = m.(X)\n",
    "cat(y,sign.(getfield.(y_fit,:data)),dims=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
